{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdtKS7WVz3HP"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import glob\n",
        "import pandas as pd\n",
        "import torch\n",
        "import random \n",
        "import numpy as np\n",
        "import tqdm \n",
        "\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "from torch import cuda\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, EarlyStoppingCallback"
      ],
      "metadata": {
        "id": "0lyiexF00JbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"results/checkpoint-6184\", num_labels=2)"
      ],
      "metadata": {
        "id": "1Y0LqJUMz9Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average='weighted')\n",
        "    p = precision_score(labels, predictions, average='weighted')\n",
        "    r = recall_score(labels, predictions, average='weighted')\n",
        "    return {\"f1\":f1, \"acc\":acc, \"prec\": p, \"recall\": r}"
      ],
      "metadata": {
        "id": "niIXH34qz_lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(int(self.labels[idx]))\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "1wpbWpp50Apx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = {}\n",
        "with open('drive/MyDrive/bug_issues.jsonl', 'r') as f:\n",
        "  for line in f:\n",
        "    json_data = json.loads(line)\n",
        "    yes = 0\n",
        "    f = set()\n",
        "    for commit in json_data[\"commits\"]:\n",
        "      for source in commit[-1]:\n",
        "        if(\".py\" in source):\n",
        "          f.add(source)\n",
        "          yes = 1 \n",
        "    if(yes):\n",
        "      dataset[json_data['issue_number']] = {}\n",
        "      dataset[json_data['issue_number']][\"body\"] = json_data[\"body\"]\n",
        "      dataset[json_data['issue_number']][\"title\"] = json_data[\"title\"]\n",
        "      dataset[json_data['issue_number']][\"commits\"] = list(f)"
      ],
      "metadata": {
        "id": "BF2Y92Yr0CAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_keys = list(dataset.keys())\n",
        "random.shuffle(dataset_keys)\n",
        "train_issues = dataset_keys[:int(len(dataset_keys)*0.9)]\n",
        "test_issues = dataset_keys[int(len(dataset_keys)*0.9):]"
      ],
      "metadata": {
        "id": "v-H2mmxD0EKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_py_files = [f for f in glob.glob(\"zulip-main/**\", recursive=True) if \".py\" in f]"
      ],
      "metadata": {
        "id": "yd3V7V-V1wsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_issues"
      ],
      "metadata": {
        "id": "Q_a19z7wF2Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pairs = []\n",
        "train_labels = []\n",
        "test_pairs = {}\n",
        "test_labels = {}\n",
        "\n",
        "# pb = tqdm.tqdm_notebook(range(len(train_issues)))\n",
        "# for issue in train_issues:\n",
        "#   text = dataset[issue][\"title\"]+dataset[issue][\"body\"]\n",
        "#   for f in dataset[issue][\"commits\"]:\n",
        "#     try:\n",
        "#       code = open(f'zulip-main/{f}', 'r').read()\n",
        "#       train_pairs.append(f'{text} </s> {code}')\n",
        "#       train_labels.append(1)\n",
        "#     except:\n",
        "#       continue \n",
        "#   count = 0\n",
        "#   while count!=2:\n",
        "#     s = random.sample(all_py_files, 1)[0]\n",
        "#     if s not in dataset[issue]['commits']:\n",
        "#       code = open(f'{s}', 'r').read()\n",
        "#       train_pairs.append(f'{text} </s> {code}')\n",
        "#       train_labels.append(0)\n",
        "#       count+=1 \n",
        "\n",
        "for issue in test_issues:\n",
        "  text = dataset[issue][\"title\"]+dataset[issue][\"body\"]\n",
        "  test_pairs[issue] = []\n",
        "  test_labels[issue] = []\n",
        "  for f in dataset[issue][\"commits\"]:\n",
        "    try:\n",
        "      code = open(f'zulip-main/{f}', 'r').read()\n",
        "      test_pairs[issue].append(f'{text} </s> {code}')\n",
        "      test_labels[issue].append(1)\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "  count = 0\n",
        "  while count!=5:\n",
        "    s = random.sample(all_py_files, 1)[0]\n",
        "    if s not in dataset[issue]['commits']:\n",
        "      code = open(s, 'r').read()\n",
        "      test_pairs[issue].append(f'{text} </s> {code}')\n",
        "      test_labels[issue].append(0)\n",
        "      count+=1 "
      ],
      "metadata": {
        "id": "iRn5A1391bj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lens = [len(test_pairs[i]) for i in test_issues]"
      ],
      "metadata": {
        "id": "YHS0y4m0EBzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lens"
      ],
      "metadata": {
        "id": "wxTeWpZVFfvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pairs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dskHl92XEXT2",
        "outputId": "8aba452e-b5b2-42d3-f930-ff855514a392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([20264, 6507, 13477, 17111, 7197, 6320, 3626, 4757, 11214, 7195, 5177, 16586, 22817, 5190, 3660, 3939, 2727, 3592, 1276, 10131, 7406, 5209, 17408, 6978, 9792, 13340, 14770, 16793, 19588, 10947, 12878, 18305, 4733, 9240, 16066, 12152, 19371, 2039, 729, 5389, 10379, 14111, 8959, 432, 2150, 3974, 20759, 20595, 11290, 2465, 1212, 16164, 12150, 7387, 9834, 5947, 18795, 1553, 3210, 4084, 6845, 17922, 8000, 784, 16850, 10991, 9913, 13533, 4000, 9866, 13060, 320, 2052, 1300, 7021, 16284, 12132, 10783, 3448, 20980, 17102, 1861, 19838, 10639, 15836, 19287, 9430, 9057, 10509, 5655, 8145, 20017, 17435, 13959, 15951, 12323, 499, 4742, 7441, 6959, 15307, 4557, 1084, 2308, 6896, 6985, 5184, 18599, 275, 13854, 6720, 2038, 11824, 13082, 23276, 22284, 11018, 4750, 5544, 4580, 12056, 19468, 13583, 9678, 18493, 7617, 11063, 7396, 2195, 878, 2232, 8582])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[7197]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FcPgQnPEHOj",
        "outputId": "1062ca5e-6a29-49ee-e771-5332df77d2d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(texts, labels):\n",
        "    encodings = tokenizer(texts, truncation=True, padding = True)\n",
        "    dataset = CustomDataset(encodings, labels)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "YR4VZcX35EKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_dataset = get_dataset(train_pairs, train_labels)\n",
        "test_dataset = get_dataset(test_pairs[7197], test_labels[7197])"
      ],
      "metadata": {
        "id": "obDVQb1j5K1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='results/',  \n",
        "    num_train_epochs=5,              \n",
        "    per_device_train_batch_size=4,  \n",
        "    per_device_eval_batch_size=8,   \n",
        "    warmup_steps=500,                \n",
        "    weight_decay=1e-4,              \n",
        "    logging_dir='logs/',            \n",
        "    logging_steps=200,\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=3,\n",
        "    evaluation_strategy=\"epoch\", \n",
        "    learning_rate = 1e-5,\n",
        "    metric_for_best_model = 'eval_loss',\n",
        "    load_best_model_at_end = True,\n",
        "    fp16=True,\n",
        "    group_by_length=True\n",
        ")"
      ],
      "metadata": {
        "id": "0hUq65IM5VBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,                         \n",
        "    args=training_args,                 \n",
        "    train_dataset=test_dataset,         \n",
        "    eval_dataset=test_dataset,             \n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZDC9bRm5aei",
        "outputId": "9481f168-3ee9-4c43-eaa4-ba5fcedfca9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cuda_amp half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ntrainer = Trainer(\n",
        "    model=model,                         \n",
        "    args=training_args,                 \n",
        "    train_dataset=train_dataset,         \n",
        "    eval_dataset=test_dataset,             \n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience = 3)]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cciqdzCuAr3q",
        "outputId": "eac3dd47-2fe9-4bd6-8ba2-88c4f904d640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cuda_amp half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 968
        },
        "id": "IFpsOLyx58Hg",
        "outputId": "369f79cb-9903-4e58-8f5a-e1b79dd4c4b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 6184\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 7730\n",
            "  Number of trainable parameters = 124647170\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6184' max='7730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6184/7730 22:43 < 05:41, 4.53 it/s, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.517300</td>\n",
              "      <td>0.725797</td>\n",
              "      <td>0.717863</td>\n",
              "      <td>0.739007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.517700</td>\n",
              "      <td>0.754823</td>\n",
              "      <td>0.724910</td>\n",
              "      <td>0.744681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.535800</td>\n",
              "      <td>0.821227</td>\n",
              "      <td>0.725075</td>\n",
              "      <td>0.730496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.511600</td>\n",
              "      <td>0.733055</td>\n",
              "      <td>0.741186</td>\n",
              "      <td>0.748936</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 705\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-1546\n",
            "Configuration saved in results/checkpoint-1546/config.json\n",
            "Model weights saved in results/checkpoint-1546/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 705\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-3092\n",
            "Configuration saved in results/checkpoint-3092/config.json\n",
            "Model weights saved in results/checkpoint-3092/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 705\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-4638\n",
            "Configuration saved in results/checkpoint-4638/config.json\n",
            "Model weights saved in results/checkpoint-4638/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 705\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to results/checkpoint-6184\n",
            "Configuration saved in results/checkpoint-6184/config.json\n",
            "Model weights saved in results/checkpoint-6184/pytorch_model.bin\n",
            "Deleting older checkpoint [results/checkpoint-3092] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from results/checkpoint-1546 (score: 0.7257971167564392).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=6184, training_loss=0.5065170216529521, metrics={'train_runtime': 1367.1274, 'train_samples_per_second': 22.617, 'train_steps_per_second': 5.654, 'total_flos': 6508315065384960.0, 'train_loss': 0.5065170216529521, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = trainer.predict(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "WMcuFb4t6AR0",
        "outputId": "7bd4ad4e-9a55-4029-f68f-6ea9bd802943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 9\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = torch.tensor(out.predictions)"
      ],
      "metadata": {
        "id": "g0FHl5HLA3mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cofNX7eFthE",
        "outputId": "b8c4944c-ecc0-49f8-ce7b-dd539e8776c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1245, -0.5166],\n",
              "        [-0.1245, -0.5166],\n",
              "        [-0.1245, -0.5166],\n",
              "        [-0.1245, -0.5166],\n",
              "        [-0.1245, -0.5166],\n",
              "        [-0.1245, -0.5166],\n",
              "        [-0.1245, -0.5166],\n",
              "        [-0.1245, -0.5166],\n",
              "        [-0.1245, -0.5166]], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "d_0-VTYQFAvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.nn.functional.softmax(preds, dim=1)"
      ],
      "metadata": {
        "id": "sTVMaDSLFBo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(out.label_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8PpW3SJ_a77",
        "outputId": "5bf5ea9e-6d6f-40a2-9712-a204130d0934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "705"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy_score(test_labels, out.label_ids)\n",
        "f1 = f1_score(test_labels, out.label_ids, average='macro')"
      ],
      "metadata": {
        "id": "2W6xqUBH_lb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRT6_51L_qFR",
        "outputId": "4e6ff0cd-079e-4954-b00f-fbb144d73284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[-2.396 ,  2.396 ],\n",
              "       [-2.398 ,  2.393 ],\n",
              "       [-2.398 ,  2.396 ],\n",
              "       ...,\n",
              "       [-0.634 ,  0.403 ],\n",
              "       [-1.453 ,  0.9067],\n",
              "       [ 1.188 , -1.82  ]], dtype=float16), label_ids=array([1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
              "       0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
              "       1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
              "       0]), metrics={'test_loss': 0.7257971167564392, 'test_f1': 0.7178626113585747, 'test_acc': 0.7390070921985815, 'test_runtime': 8.2241, 'test_samples_per_second': 85.724, 'test_steps_per_second': 10.822})"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzJWcwRH_5rt",
        "outputId": "9b49db43-8179-46fb-a859-454278ed7492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r results/checkpoint-6184 drive/MyDrive/"
      ],
      "metadata": {
        "id": "W2MY7sC1_6cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "InuUiC5-BFpl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}